---
title: 'DATA 624: Project 1'
author: 'Juliann McEachern'
date: 'October 22, 2019'
documentclass: book
subparagraph: yes
classoption: openany
output: 
  pdf_document:
    highlight: tango
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: natbib
    keep_tex: yes
    number_sections: true
    toc: yes
    toc_depth: 2
---

# Overview {-#overview}

> I am leaving the project overview page here for us to compile our final report in one singular document. We will add additional information here regarding project one to include explanation of process, etc.

## Dependencies {-#dependencies}

> Please add all libraries used here.

The following R libraries were used to complete Project 1:

```{r getting-started, echo=T, eval=T, message=F, warning=F, error=F, comment=F}
# General
library('easypackages')

libraries('knitr', 'kableExtra', 'default')

# Processing
libraries('readxl', 'tidyverse', 'janitor', 'lubridate')

# Graphing
libraries('ggplot2', 'grid', 'gridExtra', 'ggfortify','ggpubr')

# Timeseries 
libraries('urca', 'tseries', 'timetk')

# Math
libraries('forecast')
```

## Data {-#data}

Data was stored within our group repository and imported below using the `readxl` package. Each individual question was solved within an R script and the data was sourced into our main report for discussion purposes. The R scripts are available within our appendix for replication purposes. 
For grading purposes, we exported and saved all forecasts as a csv in our data folder.

```{r, eval=F}
# Data Aquisition
atm_data <- read_excel("data/ATM624Data.xlsx") 
power_data <- read_excel("data/ResidentialCustomerForecastLoad-624.xlsx") 
pipe1_data <- read_excel("data/Waterflow_Pipe1.xlsx")
pipe2_data <- read_excel("data/Waterflow_Pipe2.xlsx")

# Source Code
source("scripts/Part-A-JM.R")
```

```{r settings-A-JM, echo=F, message=F, warning=F, error=F, comment=F}
### UNIVERSAL DATA SOURCING & DEFAULT SETTINGS FOR PROJECT

# Load All Sourced Code
suppressWarnings(source("scripts/Part-A-JM&JO.R"))

# Set default augments for code chunks
knitr::opts_chunk$set(echo = F, message=F, warning=F, error=F, comment=F, fig.width=10, fig.height = 3)

# Set default augments for `kable_styling()` 
default(kable) <- list(format="latex")
default(kable_styling)  <- list(latex_options = c("HOLD_position", "striped"))
default(row_spec) <- list(row=0, bold=T)

# Set default for ggplot theme
default(theme) <- list(axis.text.x = element_text(angle = 0, hjust = NULL),
                       plot.title = element_text(color="#4c4c4c", size=12, face="bold"),
                       plot.subtitle = (element_text(size=8, color="#000000")),
                       legend.title = (element_text(size=10, color="#000000", face="bold")),
                       strip.background = element_rect(color="#000000", 
                                                       fill="#cccdd0", size=.75, linetype="solid"),
                       strip.text.x = element_text(size = 8, color = "#000000", face="bold"))

# GGplot Palette
default(scale_color_brewer) <- list(palette = 'RdPu', direction=1)
```


# Part A 

>  **Instructions:** In part A, I want you to forecast how much cash is taken out of 4 different ATM machines for May 2010.  The data is given in a single file.  The variable `Cash` is provided in hundreds of dollars, other than that it is straight forward.  I am being somewhat ambiguous on purpose.  I am giving you data, please provide your written report on your findings, visuals, discussion and your R code all within a Word readable document, except the forecast which you will put in an Excel readable file.  I must be able to cut and paste your R code and run it in R studio.  Your report must be professional - most of all - readable, EASY to follow.  Let me know what you are thinking, assumptions you are making!  Your forecast is a simple CSV or Excel file that MATCHES the format of the data I provide.

## Exploration

The data covers a period of Friday May 1, 2010 through Saturday April 30, 2010. While reviewing the data, we identified that the original data file contained `NA` values in our `ATM` and `Cash` columns for 14 observations between May 1 and 14, 2010. As these contain no information, we removed these missing values and transformed the dataset into a wide format. 

```{r, include=F}
#SILENCED CODE CHUNK FOR DISCUSSION
# Box plot hard to view and interpret with large outlier. Suggest either removing outlier or
# deleting plot.

# Examine distribution of values to identify outliers
atm_data %>% 
  group_by(ATM) %>% 
  ggplot(aes(x = ATM, y = Cash,fill=ATM)) +
  geom_boxplot() +
  labs(title="ATM Boxplot",x="", y="Cash (in hundreds)") +
  theme_bw() +
  theme(legend.position = 'none', 
        axis.text.x = element_text(angle = 45, 
                                   hjust = 1)) +
  scale_fill_brewer(palette = 'RdPu')
```

Our initial review also revealed that ATM2 contained one missing value on 2009-10-25 and that ATM4 contained a potential outlier of \$1,123 on 2010-02-09. We replaced both values with the corresponding mean value of each machine. 

We examined summary statistics for each ATM time series:  

+  ATM1 and ATM2 have pretty normal distributions; ATM1's daily mean cash dispensed is \$84, and ATM2's is \$62. 
+  ATM3 only dispensed cash on the last three days of the time series - as this provides few data points on which to forecast, we'll need to treat it specially. 
+  ATM4 has a similar mean to ATM1, but skew and kurtosis suggest the impact of an outlier Wednesday, February 10, 2010.  If this ATM is located in the Northeastern United States, this may have a relationship to a blizzard which struck on that day.  

```{r}
# plot atms as scatterplot
atm %>% 
  # re-gather observations for facet plot
  gather(key=ATM, value=Cash, ATM1,ATM2, ATM3,ATM4) %>% 
  # remove NA value from ATM2
  filter(complete.cases(.)) %>% 
  # plot 
  ggplot(aes(DATE, Cash, color=ATM)) +
  geom_point() +
  geom_smooth(method="loess") +
  facet_wrap(~ATM, scales='free_x', nrow=1) +
  labs(title="ATM Scatterplot",x="", y="Cash (in hundreds)")+
  theme_bw()+
  theme(legend.position = 'none', axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_brewer()
```

Last, we used a scatterplot to examine the correlation between cash withdrawals and dates for each machine.  We identified similiar patterns between ATM1 and ATM4, which show non-linear fluctuations that suggest a potential trend component in these timeseries. ATM2 follows a relatively linear path and decreases overtime. This changes in the last few observations, where withdrawals begin to increase. As mentioned, there are only 3 observed transactions for ATM3 that appear at the end of the captured time period. 

## Timeseries Plots 

Our cleaned dataframe was then converted into a timeseries format. The time series plots show high weekly variance, for ATM1, ATM2, and ATM4 - consistent with our takeaway from the scatterplots. 

These plots also remind us that ATM3 only dispensed cash on 3 days at the end of the timespan, with a daily range between \$82 and \$96.  Given the paucity of observations in the training data, the simplest possible approach to forecasting ATM3, averaging, is likely best.  Given that ATM3 distributed no cash until April 28, 2010, we'll assume that it was not operating until then and only include the three day window of non-zero observations in the forecast.

```{r, fig.height=5}
autoplot(atm_ts, facets = T)+
  labs(title = "Daily ATM Transactions", 
       subtitle = "Series: ATM1", y="Cash (in hundreds)", x="Weeks")+
  theme_bw()+ theme()
```

## Evaluation 

We constructed our initial timeseries for ATM1, ATM2, and ATM4 using a weekly frequency. Our ACF plots for each ATM showcases large, decreasing lags starting at 7. This pattern continues in a multiple of seven, which confirms our assumption about seasonality within the observed data. These lags are indicative of a weekly pattern. 
\newline

```{r fig.height=4}
p1<-ggAcf(ATM1_ts)+ labs(title="ACF: ATM1")+ theme_bw()+theme()
p2<-ggPacf(ATM1_ts)+ labs(title="PACF: ATM1")+ theme_bw()+ theme()
p3<-ggAcf(ATM2_ts)+ labs(title="ACF: ATM2")+ theme_bw()+theme()
p4<-ggPacf(ATM2_ts)+ labs(title="PACF: ATM2")+ theme_bw()+ theme()
p5<-ggAcf(ATM4_ts)+ labs(title="ACF: ATM4")+ theme_bw()+theme()
p6<-ggPacf(ATM4_ts)+ labs(title="PACF: ATM4")+ theme_bw()+ theme()

grid.arrange(grob=p1, p3, p5, p2, p4, p6, ncol=3)
```

Our plots further suggest that the ATM data is non-stationary. We performed a unit root test using the `ur.kpss()` function to confirm this observation. The test results below show that differencing is required on all ATM2 and ATM4 series. ATM1 falls just below the cut-off critical value, but could still benefit from differencing due to the observed seasonal pattern.   

```{r}
urATM1<-cbind("ATM"="ATM1", "No-Diff"=round(ATM1_ur@teststat,4),"Diff-1" =round(ATM1d_ur@teststat,4))

urATM2<-cbind("ATM"="ATM2", "No-Diff"=round(ATM2_ur@teststat,4),"Diff-1" =round(ATM2d_ur@teststat,4))

urATM4<-cbind("ATM"="ATM4", "No-Diff"=round(ATM4_ur@teststat,4),"Diff-1" =round(ATM4d_ur@teststat,4))

rbind(urATM1, urATM2,urATM4) %>% kable(caption="KPSS unit root test") %>% kable_styling() %>% row_spec()
```

### Modeling 

We used `auto.arima()` and set `D=1` to account for seasonal differencing of our data to select the best ARIMA models for ATM1, ATM2, and ATM4. The full models and accuracy statistics for each series can be viewed in the appendix.

*  **ATM1**: ARIMA$(0,0,2)(0,1,1)_7$ 
*  **ATM2**: ARIMA$(2,0,2)(0,1,1)_7$
*  **ATM3**: MEAN
*  **ATM4**: ARIMA$(0,0,2)(0,1,1)_7$ 

The residual ACF plots contain no pattern and the lags fall within the critical value, which suggest they are white noise and not autocorrelated. Further, the residual histograms follow a relatively normal distribution, which confirms that the models adequately fits the observed data. 

```{r}
p1<-ggAcf(ATM1_AA$residuals, lag=21)+ labs(title="ATM1", x="Lag", y="") +theme_bw()+theme()
p2<- ggpubr::gghistogram(ATM1_AA$residuals, fill="peachpuff1")+
  labs(title="ATM1", subtitle="ARIMA(0,0,2)(0,1,1)[7]",x="")+
  theme_bw()+theme()
p3<-ggAcf(ATM2_AA$residuals, lag=21)+ labs(title="ATM2",x="Lag", y="") +theme_bw()+theme()
p4<-ggpubr::gghistogram(ATM2_AA$residuals,  fill="lightpink")+
  labs(title="ATM2", subtitle="ARIMA(2,0,2)(0,1,1)[7]",x="")+
  theme_bw()+theme()
p5<-ggAcf(ATM4_AA$residuals, lag=21)+ labs(title="ATM4",x="Lag", y="") +theme_bw()+theme()
p6<-ggpubr::gghistogram(ATM4_AA$residuals,fill="deeppink4")+
  labs(title="ATM4", subtitle="ARIMA(0,0,2)(0,1,1)[7]", x="")+
  theme_bw()+theme()

grid.arrange(grob=p1, p3, p5, ncol=3, top=textGrob(label="ACF Plots of Residuals"))
             
grid.arrange(p2, p4, p6, ncol=3, top=textGrob(label="Histograms of Residuals"))
```

## Forecast

A forecast for the month of May will be 31 days in length. We applied a forecast to each series for 31 days, which span across 5 weeks, in May 2010. The numeric forecasts can be viewed in a table output in the appendix section and are also located within our data output folder.   

```{r, fig.height=10}

p1<-autoplot(ATM1_AA$fitted)+autolayer(ATM1_fc, color="peachpuff1")+
  coord_cartesian(xlim = c(40, 57.5))+
  labs(subtitle = "ATM1 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=3))

p2<-autoplot(ATM2_AA$fitted)+autolayer(ATM1_fc,  color="lightpink")+
  coord_cartesian(xlim = c(40, 57.5))+
  labs(subtitle = "ATM2 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=3))

p3<-ATM3_plotdata %>% 
  ggplot()+
  geom_line(aes(x = Date/7, y = Cash))+
  geom_line(aes(x = Date/7, y=`Point Forecast`))+
  geom_ribbon(aes(x = Date/7, ymin = `Lo 95`, ymax = `Hi 95`), linetype = 'blank', fill = 'deeppink4', alpha = .4)+
  geom_ribbon(aes(x = Date/7, ymin = `Lo 80`, ymax = `Hi 80`), linetype = 'blank', fill = 'deeppink4', alpha = .2)+
  coord_cartesian(xlim = c(40, 57.5))+labs(subtitle = "ATM3 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=3))

p4<-autoplot(ATM4_AA$fitted)+autolayer(ATM1_fc, color="darkorchid4")+
  coord_cartesian(xlim = c(40, 57.5))+
  labs(subtitle = "ATM4 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=3))

grid.arrange(p1, p2, p3, p4, ncol=1, top=textGrob(label="ATM Forecasts"))
```

# Appendix {-#Appendix}

## Part A {-#Part-A}

### ARIMA Model Summary {-#Part-A-arima}

**`ATM1`:**
```{r}
ATM1_AA
```

**`ATM2`:**
```{r}
ATM2_AA
```

**`ATM3`:**
```{r}
cat('Mean of non-zero values is', round(mean(ATM3_ts[ATM3_ts > 0]), 2))
```

**`ATM4`:**
```{r}
ATM4_AA
```

### Point Forecasts {-#Part-A-FC}

```{r}
ATM_FC %>% kable(caption="ATM Mean Point Forecast") %>% kable_styling() %>% row_spec()
```

\newpage
### R Script {-#Part-A-RScript}

```{r, echo=T, eval=F}
# Dependencies
## processing
library(readxl)
library(tidyverse)
library(janitor)

## forecasting packages
library(urca)
library(forecast)
library(fpp2)

# Load data
atm_data <- read_excel("data/ATM624Data.xlsx") 

# clean dataframe
atm <- atm_data %>% 
  # create wide dataframe
  spread(ATM, Cash) %>% 
  # remove NA column using function from janitor package
  remove_empty(which = "cols") %>%
  # filter unobserved values from May 2010
  filter(DATE < as.Date("2010-05-01")) %>%
  # ensure dates are ascending
  arrange(DATE) 

atm$ATM2[is.na(atm$ATM2)] <- mean(atm$ATM2, na.rm = TRUE) ## remove NA
atm$ATM4[which.max(atm$ATM4)] <- mean(atm$ATM4, na.rm = TRUE) ## remove outlier

# create TS with weekly frequency & subset data
atm_ts <- atm %>% select(-DATE) %>% ts(start=1,  frequency = 7)
ATM1_ts <- atm_ts[,1]; ATM2_ts <- atm_ts[,2]; ATM3_ts <- atm_ts[,3]; ATM4_ts <- atm_ts[,4]

#unit root test
## no diff
ATM1_ur <-ur.kpss(ATM1_ts)
ATM2_ur <-ur.kpss(ATM2_ts)
ATM4_ur <-ur.kpss(ATM4_ts)
## first order diff
ATM1d_ur <-ur.kpss(diff(ATM1_ts, lag=7))
ATM2d_ur <-ur.kpss(diff(ATM2_ts, lag=7))
ATM4d_ur <-ur.kpss(diff(ATM4_ts, lag=7))

# AUTO.ARIMA function; set D=1 for seasonal differencing
ATM1_AA <-auto.arima(ATM1_ts, D = 1, lambda = "auto", approximation = F, stepwise = T)
ATM2_AA <-auto.arima(ATM2_ts, D = 1, lambda = "auto", approximation = F, stepwise = T)
ATM4_AA <-auto.arima(ATM4_ts, D = 1, lambda = "auto", approximation = F, stepwise = T)

# Forecast Results
ATM1_fc <- forecast(ATM1_AA,h=31)
ATM2_fc <- forecast(ATM2_AA,h=31)
ATM3_fc <- meanf(ATM3_ts[ATM3_ts > 0], h=31)# based on three non-zero values (between observations 363 and 365)
ATM4_fc <- forecast(ATM4_AA,h=31)

# Prepare dataframe for ATM3 mean forcast plotting 
ATM3_plotdata_fc <- cbind(seq(from = 366, to = 396),
                          ATM3_fc[[5]], 
                          ATM3_fc[[6]], 
                          ATM3_fc[[7]]) %>% 
  as.data.frame()

colnames(ATM3_plotdata_fc) <- c('Date', 'Point Forecast', 'Lo 80', 'Lo 95', 'Hi 80', 'Hi 95')
ATM3_plotdata <- ATM3_ts %>% 
  fortify() %>% 
  select(-Index) %>%
  rename(Cash = Data) %>% 
  mutate(Date = as.numeric(row.names(.))) %>% 
  select(Date, Cash) %>% 
  full_join(ATM3_plotdata_fc, by = 'Date')

#Revert results back into original form
date <- as.character(seq(as.Date('2010-05-01'), length.out=31, by=1))
ATM_FC <-  cbind("Date"=date, 
                 "ATM1"=ATM1_fc$mean, 
                 "ATM2"=ATM2_fc$mean,
                 "ATM3"=ATM3_fc$mean,
                 "ATM4"=ATM4_fc$mean) %>% as.data.frame()

write_csv(ATM_FC, path = "forecasts/ATM_all_forecast.csv")
```

