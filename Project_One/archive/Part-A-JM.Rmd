---
title: 'DATA 624: Project 1'
author: 'Juliann McEachern'
date: 'October 22, 2019'
documentclass: book
subparagraph: yes
classoption: openany
output: 
  pdf_document:
    highlight: tango
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: natbib
    keep_tex: yes
    number_sections: true
    toc: yes
    toc_depth: 2
---

# Overview {-#overview}

> I am leaving the project overview page here for us to compile our final report in one singular document. We will add additional information here regarding project one to include explanation of process, etc.

## Dependencies {-#dependencies}

> Please add all libraries used here.

The following R libraries were used to complete Project 1:

```{r getting-started, echo=T, eval=T, message=F, warning=F, error=F, comment=F}
# General
library('easypackages')

libraries('knitr', 'kableExtra', 'default')

# Processing
libraries('readxl', 'tidyverse', 'janitor', 'lubridate')

# Graphing
libraries('ggplot2', 'grid', 'gridExtra', 'ggfortify','ggpubr')

# Timeseries 
libraries('zoo', 'urca', 'tseries', 'timetk')

# Math
libraries('forecast')
```

## Data {-#data}

Data was stored within our group repository and imported below using the `readxl` package. Each individual question was solved within an R script and the data was sourced into our main report for discussion purposes. The R scripts are available within our appendix for replication purposes. 

For grading purposes, we exported and saved all forecasts as a csv in our data folder.

```{r, eval=F}
# Data Aquisition
atm_data <- read_excel("data/ATM624Data.xlsx") 
power_data <- read_excel("data/ResidentialCustomerForecastLoad-624.xlsx") 
pipe1_data <- read_excel("data/Waterflow_Pipe1.xlsx")
pipe2_data <- read_excel("data/Waterflow_Pipe2.xlsx")

# Source Code
source("scripts/Part-A-JM.R")
```

```{r settings-A-JM, echo=F, message=F, warning=F, error=F, comment=F}
### UNIVERSAL DATA SOURCING & DEFAULT SETTINGS FOR PROJECT

# Load All Sourced Code
suppressWarnings(source("scripts/Part-A-JM.R"))

# Set default augments for code chunks
knitr::opts_chunk$set(echo = F, message=F, warning=F, error=F, comment=F, fig.width=10, fig.height = 3)

# Set default augments for `kable_styling()` 
default(kable) <- list(format="latex")
default(kable_styling)  <- list(latex_options = c("HOLD_position", "striped"))
default(row_spec) <- list(row=0, bold=T)

# Set default for ggplot theme
default(theme) <- list(axis.text.x = element_text(angle = 0, hjust = NULL),
                       plot.title = element_text(color="#4c4c4c", size=12, face="bold"),
                       plot.subtitle = (element_text(size=8, color="#000000")),
                       legend.title = (element_text(size=10, color="#000000", face="bold")),
                       strip.background = element_rect(color="#000000", 
                                                       fill="#cccdd0", size=.75, linetype="solid"),
                       strip.text.x = element_text(size = 8, color = "#000000", face="bold"))

# GGplot Palette
default(scale_color_brewer) <- list(palette = 'RdPu', direction=1)
```


# Part A 

>  **Instructions:** In part A, I want you to forecast how much cash is taken out of 4 different ATM machines for May 2010.  The data is given in a single file.  The variable `Cash` is provided in hundreds of dollars, other than that it is straight forward.  I am being somewhat ambiguous on purpose.  I am giving you data, please provide your written report on your findings, visuals, discussion and your R code all within a Word readable document, except the forecast which you will put in an Excel readable file.  I must be able to cut and paste your R code and run it in R studio.  Your report must be professional - most of all - readable, EASY to follow.  Let me know what you are thinking, assumptions you are making!  Your forecast is a simple CSV or Excel file that MATCHES the format of the data I provide.

## Exploration

Through data exploration, we identified that the original data file contained `NA` values in our `ATM` and `Cash` columns for 14 observations in May 2010. We removed these missing values and transformed the dataset into a wide format.  Our cleaned dataframe was then converted into a timeseries format using the `zoo` package for forecasting in the next section. Our initial review of the data showed that ATM2 contained one missing value on 2009-10-25 and that ATM4 contained a potential outlier of $1123 on 2010-02-09. We replaced both values with the corresponding mean value of each machine. 

Next, we used a scatterplot to take an initial look at the correlation between cash withdrawals and dates for each machine.  We can identified similiar patterns between ATM1 and ATM4, which show non-linear fluxuations that suggest a potential trend component in these timeseries. ATM2 follows a relatively linear path and decreases overtime. This changes in the last few observations, where withdrawals begin to increase. There are only 3 observed transactions for ATM3 that appear at the end of the captured time period. 

```{r}
# plot atms as scatterplot
atm %>% 
  # re-gather observations for facet plot
  gather(key=ATM, value=Cash, ATM1,ATM2, ATM3,ATM4) %>% 
  # remove NA value from ATM2
  filter(complete.cases(.)) %>% 
  # plot 
  ggplot(aes(DATE, Cash, color=ATM)) +
  geom_point() +
  geom_smooth(method="loess") +
  facet_wrap(~ATM, scales='free_x', nrow=1) +
  labs(title="ATM Scatterplot",x="", y="Cash (in hundreds)")+
  theme_bw()+
  theme(legend.position = 'none', axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_brewer()
```

## Timeseries Plots 

The time series plots show high weekly variance as suspected in from our scatterplots. We can see again that time series for ATM3 only contains 3 transactions, thus we deemed this series not suitable for modeling and forecasting. As a result, our following sections will not include extrapolation on this series.

```{r, fig.height=4}
autoplot(atm_ts, facets = T)+
  labs(title = "Daily ATM Transactions", y="Cash (in hundreds)", x="Weeks")+
  theme_bw()+ theme()
```

## Evaluation 

We constructed our initial timeseries using a weekly frequency. Our ACF plots for each ATM showcases large, decreasing lags starting at 7. This pattern continues in a multiple of seven, which confirms our assumption about seasonality within the observed data. These lags are indicative of a weekly pattern. 

```{r fig.height=4}
p1<-ggAcf(ATM1_ts)+ labs(title="ACF: ATM1", x="")+ theme_bw()+theme()
p2<-ggPacf(ATM1_ts)+ labs(title="PACF: ATM1", x="")+ theme_bw()+ theme()
p3<-ggAcf(ATM2_ts)+ labs(title="ACF: ATM2", x="")+ theme_bw()+theme()
p4<-ggPacf(ATM2_ts)+ labs(title="PACF: ATM2", x="")+ theme_bw()+ theme()
p5<-ggAcf(ATM4_ts)+ labs(title="ACF: ATM4", x="")+ theme_bw()+theme()
p6<-ggPacf(ATM4_ts)+ labs(title="PACF: ATM4", x="")+ theme_bw()+ theme()

grid.arrange(grob=p1, p3, p5, p2, p4, p6, ncol=3)
```

Our plots further suggest that the ATM data is non-stationary. We performed a unit root test using the `ur.kpss()` function to confirm this observation. The test results below show that differencing is required on all ATM2 and ATM4 series. ATM1 falls just below the cut-off critical value, but could still use differencing due to the observed seasonal pattern.   

```{r}
urATM1<-cbind("ATM"="ATM1", "No-Diff"=round(ATM1_ur@teststat,4),"Diff-1" =round(ATM1d_ur@teststat,4))

urATM2<-cbind("ATM"="ATM2", "No-Diff"=round(ATM2_ur@teststat,4),"Diff-1" =round(ATM2d_ur@teststat,4))

urATM4<-cbind("ATM"="ATM4", "No-Diff"=round(ATM4_ur@teststat,4),"Diff-1" =round(ATM4d_ur@teststat,4))

rbind(urATM1, urATM2,urATM4) %>% kable(caption="KPSS unit root test") %>% kable_styling() %>% row_spec()
```

### Modeling 

We used `auto.arima()` and set `D=1` to account for seasonal differencing of our data to select the best ARIMA models. The full models and accuracy statistics for each series can be viewed in the appendix.

*  **ATM1**: ARIMA$(0,0,2)(0,1,1)_7$ 
*  **ATM2**: ARIMA$(2,0,2)(0,1,1)_7$
*  **ATM4**: ARIMA$(0,0,2)(0,1,1)_7$ 

The following ACF plots show us that our differentiated data is now stationary. Further, the residual histograms follow a relatively normal distribution, which confirms that the models adequately fits the observed data. 

```{r, fig.height=2.75}
p1<-ggAcf(ATM1_AA$residuals, lag=21)+ labs(title="ATM1", x="", y="") +theme_bw()+theme()
p2<-ggAcf(ATM2_AA$residuals, lag=21)+ labs(title="ATM2",x="", y="") +theme_bw()+theme()
p3<-ggAcf(ATM4_AA$residuals, lag=21)+ labs(title="ATM4",x="", y="") +theme_bw()+theme()

grid.arrange(grob=p1, p2, p3, ncol=3, top=textGrob(label="ACF Plots"))

p1<- ggpubr::gghistogram(ATM1_AA$residuals, fill="peachpuff1")+
  labs(title="ATM1", subtitle="ARIMA(0,0,2)(0,1,1)[7]",x="")+
  theme_bw()+theme()
p2<-ggpubr::gghistogram(ATM2_AA$residuals,  fill="lightpink")+
  labs(title="ATM2", subtitle="ARIMA(2,0,2)(0,1,1)[7]",x="")+
  theme_bw()+theme()
p3<-ggpubr::gghistogram(ATM4_AA$residuals,fill="deeppink4")+
  labs(title="ATM4", subtitle="ARIMA(0,0,2)(0,1,1)[7]", x="")+
  theme_bw()+theme()
grid.arrange(p1, p2, p3, ncol=3, top=textGrob(label="Residuals Plots"))
```

## Forecast

Finally, we applied a forecast to each series for 31 days to predict cash withdrawals in May 2010. The forecast spans across 5 weeks and follows similiar trend and seasonality to the fitted data. The numeric forecasts can be viewed in a table output in the appendix section and are also located within our data output folder.   

```{r}
p1<-autoplot(ATM1_AA$fitted)+autolayer(ATM1_fc, color="peachpuff1")+
  coord_cartesian(xlim = c(40, 57.5))+
  labs(subtitle = "ATM1 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=4))
p2<-autoplot(ATM2_AA$fitted)+autolayer(ATM1_fc,  color="lightpink")+
  coord_cartesian(xlim = c(40, 57.5))+
  labs(subtitle = "ATM2 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=4))
p3<-autoplot(ATM4_AA$fitted)+autolayer(ATM1_fc, color="deeppink4")+
  coord_cartesian(xlim = c(40, 57.5))+
  labs(subtitle = "ATM4 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=4))

grid.arrange(p1, p2, p3, ncol=3, top=textGrob(label="ATM Forecasts"))
```

# Appendix {-#Appendix}

## Part A {-#Part-A}

### ARIMA Model Summary {-#Part-A-arima}

**`ATM1`:**
```{r}
ATM1_AA
```

**`ATM2`:**
```{r}
ATM2_AA
```

**`ATM4`:**
```{r}
ATM4_AA
```

### Point Forecasts {-#Part-A-FC}

```{r}
ATM_FC %>% kable(caption="ATM Mean Point Forecast") %>% kable_styling() %>% row_spec()
```

\newpage
### R Script {-#Part-A-RScript}

```{r, echo=T, eval=F}
# load data
atm_data <- read_excel("data/ATM624Data.xlsx") 

# clean dataframe
atm <- atm_data %>% 
  # create wide dataframe
  spread(ATM, Cash) %>% 
  # remove NA column using function from janitor package
  remove_empty(which = "cols") %>%
  # filter unobserved values from May 2010
  filter(DATE < as.Date("2010-05-01")) %>%
  # ensure dates are ascending
  arrange(DATE) 

atm$ATM2[is.na(atm$ATM2)] <- mean(atm$ATM2, na.rm = TRUE) ## remove NA
atm$ATM4[which.max(atm$ATM4)] <- mean(atm$ATM4, na.rm = TRUE) ## remove outlier

# create TS with weekly frequency & subset data
atm_ts <- atm %>% select(-DATE) %>% ts(start=1,  frequency = 7)
ATM1_ts <- atm_ts[,1]; ATM2_ts <- atm_ts[,2]; ATM4_ts <- atm_ts[,4]

#unit root test
## no diff
ATM1_ur <-ur.kpss(ATM1_ts)
ATM2_ur <-ur.kpss(ATM2_ts)
ATM4_ur <-ur.kpss(ATM4_ts)
## first order diff
ATM1d_ur <-ur.kpss(diff(ATM1_ts, lag=7))
ATM2d_ur <-ur.kpss(diff(ATM2_ts, lag=7))
ATM4d_ur <-ur.kpss(diff(ATM4_ts, lag=7))

# AUTO.ARIMA function; set D=1 for seasonal differencing
ATM1_AA <-auto.arima(ATM1_ts, D = 1, lambda = "auto", approximation = F, stepwise = T)
ATM2_AA <-auto.arima(ATM2_ts, D = 1, lambda = "auto", approximation = F, stepwise = T)
ATM4_AA <-auto.arima(ATM4_ts, D = 1, lambda = "auto", approximation = F, stepwise = T)

# Forecast Results
ATM1_fc <- forecast(ATM1_AA,h=31)
ATM2_fc <- forecast(ATM2_AA,h=31)
ATM4_fc <- forecast(ATM4_AA,h=31)

# Revert results back into original form
date <- as.character(seq(as.Date('2010-05-01'), length.out=31, by=1))
ATM_FC <-  cbind("Date"=date, "ATM1"=ATM1_fc$mean, "ATM2"=ATM2_fc$mean,
                 "ATM3"=c(NA,NA,NA,NA),"ATM4"=ATM4_fc$mean) %>% as.data.frame()

# Save output
write.csv(ATM_FC, file="forecasts/ATM_ARIMA_FC.csv")
```



